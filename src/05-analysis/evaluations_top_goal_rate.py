# -*- coding: utf-8 -*-
"""ken_evaluations_top_goal_rate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vdOKpwya38IaM4swierd99tk-ObwIipL
"""

from tqdm import tqdm, trange
import numpy as np
import pandas as pd

from keras.models import load_model

from google.colab import drive
drive.mount('/content/drive')

filepath = "drive/Team Drives/Deep Learning Project/models/cnn_64_fixed.model"
model = load_model(filepath)
model.summary()

data_fp = "drive/Team Drives/Deep Learning Project/ken_cnn/combined_text_dataset.csv"
df = pd.read_csv(data_fp, sep='\t')
if 'Unnamed: 0' in df.columns:
  df.drop('Unnamed: 0', axis=1, inplace=True) # Drop unused column
df.head(3)

# Select only top team to see result performance
top_team_names = [
    'AS Roma', 'Atletico Madrid', 'Barcelona', 'Bayern Munich', 'Borussia Dortmund',
    'Juventus', 'Lyon', 'Napoli', 'Paris Saint-Germain', 'Real Madrid']

df.shape

def get_top_team_won(df, top_team_names):
  indexes = []
  for i in trange(df.shape[0]):
    ht = df.iloc[i]['ht']
    at = df.iloc[i]['at']
    if (ht in top_team_names) or (at in top_team_names):
      indexes.append(i)
    
  return df.iloc[indexes]

top_team_df = get_top_team_won(df, top_team_names)

top_team_df.shape

top_team_df.head(3)

"""Feature Engineering"""

# num_words = len(unique_words)
num_words = 200 # Most 1000 common words

# Tokenization
from keras.preprocessing.text import Tokenizer
samples = list(df.text)
# Creates a tokenizer, configured to only take into account the <num_words> most common words
tokenizer = Tokenizer(num_words=num_words)
# Building the word index
tokenizer.fit_on_texts(samples)

# Turns strings into lists of integer indices
sequences = tokenizer.texts_to_sequences(list(top_team_df.text))

# Preprocessing
from keras import preprocessing
max_len = 1132
x_test = preprocessing.sequence.pad_sequences(sequences, maxlen=max_len)
x_test.shape

# Evaluation
actuals = list(top_team_df['winner'])
predictions = model.predict(x_test)
predictions.shape

predictions[0]

def get_label(dist):
  max_idx = np.argmax(dist)
  if max_idx == 0:
    return 'home'
  elif max_idx == 1:
    return 'tie'
  else:
    return 'away'

y_true = list(top_team_df['winner'])
y_pred = [ get_label(dist) for dist in predictions ]

# Evaluate performance
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_recall_fscore_support

a = accuracy_score(y_true, y_pred)
p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')

print('Accuracy: {}'.format(a))
print('Precision: {}'.format(p))
print('Recall: {}'.format(r))
print('F1-score: {}'.format(f1))

# Evaluate performance
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_recall_fscore_support

a = accuracy_score(y_true, y_pred)
p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='micro')

print('Accuracy: {}'.format(a))
print('Precision: {}'.format(p))
print('Recall: {}'.format(r))
print('F1-score: {}'.format(f1))